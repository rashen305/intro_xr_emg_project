# âš¡ï¸ Machine Learning Subdirectory
This folder contains all logic related to training and evaluating a neural network to statically recognize different gestures.
We additionally provide for real-time inferencing based on incoming streaming EMG sensor data via TCP socket.

---

## ğŸ“‚ Project File Tree
The project structure assumes the core Python modules and notebooks are contained within an `ml/` subdirectory, and the raw data is stored in a `myo/samples/` folder.

```
intro_xr_emg_project/
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ cnn_model.py                # CNN Architecture & Training Module (PyTorch)
â”‚   â”œâ”€â”€ emg_preprocessing.py        # Data Processing Logic (Filtering, STFT, Dataset)
â”‚   â”œâ”€â”€ train.ipynb                 # Primary Training Notebook
â”‚   â”œâ”€â”€ evaluate.ipynb              # Evaluation/Verification Notebook
â”‚   â”œâ”€â”€ README.md                   # Project Documentation (This file)
â”‚   â”œâ”€â”€ **init**.py                 # Makes 'ml' a Python package (Recommended)
â”‚   â””â”€â”€ normalization_params.npy    # ğŸ’¾ GENERATED: Data Mean and Standard Deviation
â”œâ”€â”€ myo/
â”‚   â””â”€â”€ samples/
â”‚       â”œâ”€â”€ raymond_arm_90_deg_200hz.csv       # ğŸ“Š Input Data File (Example)
â”‚       â””â”€â”€ raymond_arm_down_pinch_200hz.csv   # ğŸ“Š Input Data File (Example)
â”œâ”€â”€ emg-to-pytorch.cpp              # ğŸ–¥ï¸ Live Data Acquisition (C++ Myo SDK)
â””â”€â”€ [Other Project Files...]
```

---

## ğŸ’¡ File Descriptions

| File / Module | Function | Details |
| :--- | :--- | :--- |
| **`cnn_model.py`** | **Model & Training Module** | Defines the **`CNNmodel`** class, which contains the complete 2D-CNN architecture. Importantly, it includes integrated methods (`train_epoch`, `test_epoch`, and the high-level `train`) that encapsulate the optimization, loss, and full training loop logic. |
| **`emg_preprocessing.py`** | **Data Pipeline** | Contains all constant definitions, filtering methods (`preprocess`), and the PyTorch **`EMGDataset`** class. It ensures consistent EMG signal preprocessing (detrending, filtering, STFT) across all stages. |
| **`train.ipynb`** | **Training Script** | Loads data, calculates and saves **normalization parameters**, initializes the `CNNmodel`, and executes the full training process via `model.train()`. It saves the final model weights. |
| **`evaluate.ipynb`** | **Verification Script** | Loads a pre-trained model and normalization parameters to assess performance on new or test data and visualizes the results (Confusion Matrix). |
| **`normalization_params.npy`** | **Critical Metadata** | A NumPy binary file containing the **global mean ($\mu$) and standard deviation ($\sigma$)** calculated *only* from the training data. This must be used to scale all future input data. |
| **`*.pth`** | **Model Output** | The file containing the PyTorch **state dictionary** (weights and biases) of the trained `CNNmodel` after all epochs are complete. |

---

## ğŸš€ Execution Workflow
The project is designed for a modular, two-stage execution:

### 1. Training (Run `train_cnn.ipynb`)
This is the only stage where the model learns and where the normalization parameters are calculated.

1.  Set configuration (`EPOCHS`, `LR`, etc.) in the notebook.
2.  Data is preprocessed, and the global mean/std are computed.
3.  The **`normalization_params.npy`** file is generated.
4.  The model runs its full training cycle (`model.train(...)`).
5.  The final, fully trained model state is saved to **`train_single_subject_myo_model.pth`**.

### 2. Evaluation (Run `evaluate.ipynb`)
This stage verifies the model's generalization ability.

1.  The script loads **`normalization_params.npy`** and **`train_single_subject_myo_model.pth`**.
2.  Evaluation data is preprocessed and scaled using the loaded mean/std.
3.  The model runs its `test_epoch` to generate final accuracy and the Confusion Matrix.